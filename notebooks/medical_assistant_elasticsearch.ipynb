{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "828f88b9-9ee8-4a25-8ed3-3c495abd6c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Dict\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32415914-2fe5-4f59-85f0-32d17a737dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv('/home/ubuntu/medical_assistant_rag/.envrc')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e440cb-d4c7-4382-a90c-56b3e788d745",
   "metadata": {},
   "source": [
    "## Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d33b5af2-4c7e-4609-bf6a-ed96dd5226df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>medical_department</th>\n",
       "      <th>condition_type</th>\n",
       "      <th>patient_demographics</th>\n",
       "      <th>common_symptoms</th>\n",
       "      <th>treatment_or_management</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A 23-year-old pregnant woman at 22 weeks gesta...</td>\n",
       "      <td>Nitrofurantoin</td>\n",
       "      <td>Obstetrics &amp; Gynecology</td>\n",
       "      <td>Infectious</td>\n",
       "      <td>Age Group: Adult, Gender: Female, Pregnancy St...</td>\n",
       "      <td>Burning sensation (e.g., urination)</td>\n",
       "      <td>Medication</td>\n",
       "      <td>Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A 3-month-old baby died suddenly at night whil...</td>\n",
       "      <td>Placing the infant in a supine position on a f...</td>\n",
       "      <td>Pediatrics</td>\n",
       "      <td>Idiopathic</td>\n",
       "      <td>Age Group: Infant (1-12 months), Gender: Male,...</td>\n",
       "      <td>Fever, Altered Mental Status</td>\n",
       "      <td>Preventive Measures (e.g., vaccinations)</td>\n",
       "      <td>Life-threatening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A mother brings her 3-week-old infant to the p...</td>\n",
       "      <td>Abnormal migration of ventral pancreatic bud</td>\n",
       "      <td>Pediatrics</td>\n",
       "      <td>Infectious</td>\n",
       "      <td>Age Group: Neonate (0-28 days), Gender: Male, ...</td>\n",
       "      <td>Fussiness, Nausea/Vomiting</td>\n",
       "      <td>Observation/Monitoring</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A pulmonary autopsy specimen from a 58-year-ol...</td>\n",
       "      <td>Thromboembolism</td>\n",
       "      <td>Pulmonology</td>\n",
       "      <td>Acute</td>\n",
       "      <td>Age Group: Adult, Gender: Female, Pregnancy St...</td>\n",
       "      <td>Dyspnea (Shortness of breath), Fatigue</td>\n",
       "      <td>Supportive Care (e.g., oxygen therapy)</td>\n",
       "      <td>Life-threatening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A 20-year-old woman presents with menorrhagia ...</td>\n",
       "      <td>Von Willebrand disease</td>\n",
       "      <td>Obstetrics &amp; Gynecology</td>\n",
       "      <td>Chronic</td>\n",
       "      <td>Age Group: Adult, Gender: Female, Pregnancy St...</td>\n",
       "      <td>Bleeding (e.g., menorrhagia), Easy bruising</td>\n",
       "      <td>Medication</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           question  \\\n",
       "0   0  A 23-year-old pregnant woman at 22 weeks gesta...   \n",
       "1   1  A 3-month-old baby died suddenly at night whil...   \n",
       "2   2  A mother brings her 3-week-old infant to the p...   \n",
       "3   3  A pulmonary autopsy specimen from a 58-year-ol...   \n",
       "4   4  A 20-year-old woman presents with menorrhagia ...   \n",
       "\n",
       "                                              answer       medical_department  \\\n",
       "0                                     Nitrofurantoin  Obstetrics & Gynecology   \n",
       "1  Placing the infant in a supine position on a f...               Pediatrics   \n",
       "2       Abnormal migration of ventral pancreatic bud               Pediatrics   \n",
       "3                                    Thromboembolism              Pulmonology   \n",
       "4                             Von Willebrand disease  Obstetrics & Gynecology   \n",
       "\n",
       "  condition_type                               patient_demographics  \\\n",
       "0     Infectious  Age Group: Adult, Gender: Female, Pregnancy St...   \n",
       "1     Idiopathic  Age Group: Infant (1-12 months), Gender: Male,...   \n",
       "2     Infectious  Age Group: Neonate (0-28 days), Gender: Male, ...   \n",
       "3          Acute  Age Group: Adult, Gender: Female, Pregnancy St...   \n",
       "4        Chronic  Age Group: Adult, Gender: Female, Pregnancy St...   \n",
       "\n",
       "                               common_symptoms  \\\n",
       "0          Burning sensation (e.g., urination)   \n",
       "1                 Fever, Altered Mental Status   \n",
       "2                   Fussiness, Nausea/Vomiting   \n",
       "3       Dyspnea (Shortness of breath), Fatigue   \n",
       "4  Bleeding (e.g., menorrhagia), Easy bruising   \n",
       "\n",
       "                    treatment_or_management          severity  \n",
       "0                                Medication              Mild  \n",
       "1  Preventive Measures (e.g., vaccinations)  Life-threatening  \n",
       "2                    Observation/Monitoring          Moderate  \n",
       "3    Supportive Care (e.g., oxygen therapy)  Life-threatening  \n",
       "4                                Medication          Moderate  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/data_metadata_small.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89669b5e-5669-4f53-81d2-e5f37024ffaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14c03f88-e4cb-4982-b198-0032be90902f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'question': 'A 23-year-old pregnant woman at 22 weeks gestation presents with burning upon urination. She states it started 1 day ago and has been worsening despite drinking more water and taking cranberry extract. She otherwise feels well and is followed by a doctor for her pregnancy. Her temperature is 97.7°F (36.5°C), blood pressure is 122/77 mmHg, pulse is 80/min, respirations are 19/min, and oxygen saturation is 98% on room air. Physical exam is notable for an absence of costovertebral angle tenderness and a gravid uterus. Which of the following is the best treatment for this patient?',\n",
       " 'answer': 'Nitrofurantoin',\n",
       " 'medical_department': 'Obstetrics & Gynecology',\n",
       " 'condition_type': 'Infectious',\n",
       " 'patient_demographics': 'Age Group: Adult, Gender: Female, Pregnancy Status: Pregnant',\n",
       " 'common_symptoms': 'Burning sensation (e.g., urination)',\n",
       " 'treatment_or_management': 'Medication',\n",
       " 'severity': 'Mild'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = df.to_dict(orient='records')\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a27a0aa-2216-4b76-b432-3388b8be3820",
   "metadata": {},
   "source": [
    "## Elastic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93bdbdb7-ce3c-4b72-b1ca-aba3cfa8c7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bee77e40-3367-4bf8-9f1b-328cf7e8580f",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_url = 'http://localhost:9200'\n",
    "es_client = Elasticsearch(es_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b91b106-f72e-4eb9-b096-1929f2048237",
   "metadata": {},
   "source": [
    "Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24080524-9cbf-47c8-b99c-3b34a18b4a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"id\": {\"type\": \"keyword\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"answer\": {\"type\": \"text\"},\n",
    "            \"medical_department\": {\"type\": \"keyword\"},\n",
    "            \"condition_type\": {\"type\": \"keyword\"},\n",
    "            \"patient_demographics\": {\"type\": \"text\"},\n",
    "            \"common_symptoms\": {\"type\": \"text\"},\n",
    "            \"treatment_or_management\": {\"type\": \"text\"},\n",
    "            \"severity\": {\"type\": \"keyword\"},\n",
    "            \"question_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"answer_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"question_answer_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "995f2611-0de6-44d9-96dc-992f5049cfb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'medical-questions'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"medical-questions\"\n",
    "\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00014ee3-e5ed-420e-9a21-0cf2c0717643",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/share/virtualenvs/medical_assistant_rag-1u8aKuup/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('sentence-transformers/multi-qa-MiniLM-L6-cos-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1841be42-24a0-4935-8984-0c0b9c638afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bfc753366534f7ca0fb463b2f461487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    question = doc.get('question', 'No question provided')\n",
    "    answer = doc.get('answer', 'No answer provided')\n",
    "    qa_combined = question + ' ' + answer\n",
    "\n",
    "    doc['question'] = question\n",
    "    doc['answer'] = answer\n",
    "    doc['question_vector'] = model.encode(question).tolist()\n",
    "    doc['answer_vector'] = model.encode(answer).tolist()\n",
    "    doc['question_answer_vector'] = model.encode(qa_combined).tolist()\n",
    "\n",
    "    # Use the document's 'id' field as the Elasticsearch document ID\n",
    "    es_client.index(index=index_name, id=doc['id'], document=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c739140d-065d-43e8-ac83-4389f932c825",
   "metadata": {},
   "source": [
    "Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1093a838-7628-455d-824d-e764a4bbab5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c79bcc7-b70b-466b-a27c-56e40e46ee93",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"A 30-year-old woman in her second trimester of pregnancy presents with symptoms of dysuria and urinary urgency. She has no significant medical history and is not allergic to any medications. Physical examination and vital signs are within normal limits. Which antibiotic is considered safe and effective for treating her urinary tract infection during pregnancy?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a48633-0ee9-482a-8f74-3c6bee9d82bc",
   "metadata": {},
   "source": [
    "Embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92470f1a-982a-42b2-8cbd-ca489024734c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13973/4103590305.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = SentenceTransformerEmbeddings(model_name=\"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\")\n",
      "/home/ubuntu/.local/share/virtualenvs/medical_assistant_rag-1u8aKuup/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embeddings = SentenceTransformerEmbeddings(model_name=\"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b6d47ed-0632-4a36-b53c-ded7f78c3fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_query_rrf(search_query: str) -> List[Dict]:\n",
    "    vector = embeddings.embed_query(search_query)\n",
    "    k = 60\n",
    "\n",
    "    knn_query = {\n",
    "        \"field\": \"question_answer_vector\",\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": 10,\n",
    "        \"num_candidates\": 10000,\n",
    "        \"boost\": 0.5,\n",
    "    }\n",
    "\n",
    "    keyword_query = {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": search_query,\n",
    "                    \"fields\": [\n",
    "                        \"question\",\n",
    "                        \"answer\",\n",
    "                        \"common_symptoms\",\n",
    "                        \"condition_type\",\n",
    "                        \"medical_department\",\n",
    "                        \"patient_demographics\"\n",
    "                    ],\n",
    "                    \"type\": \"best_fields\",\n",
    "                    \"boost\": 0.5,\n",
    "                }\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "\n",
    "    source_fields = [\n",
    "        \"id\", \"question\", \"answer\", \"medical_department\", \"condition_type\",\n",
    "        \"patient_demographics\", \"common_symptoms\", \"treatment_or_management\", \"severity\"\n",
    "    ]\n",
    "\n",
    "    knn_response = es_client.search(\n",
    "        index=index_name,\n",
    "        body={\n",
    "            \"knn\": knn_query,\n",
    "            \"size\": 10,\n",
    "            \"_source\": source_fields\n",
    "        }\n",
    "    )\n",
    "    knn_results = knn_response['hits']['hits']\n",
    "\n",
    "    keyword_response = es_client.search(\n",
    "        index=index_name,\n",
    "        body={\n",
    "            \"query\": keyword_query,\n",
    "            \"size\": 10,\n",
    "            \"_source\": source_fields\n",
    "        }\n",
    "    )\n",
    "    keyword_results = keyword_response['hits']['hits']\n",
    "\n",
    "    def compute_rrf(rank, k=60):\n",
    "        return 1.0 / (k + rank)\n",
    "\n",
    "    rrf_scores = {}\n",
    "    for rank, hit in enumerate(knn_results):\n",
    "        doc_id = hit['_id']\n",
    "        score = compute_rrf(rank + 1, k)\n",
    "        rrf_scores[doc_id] = rrf_scores.get(doc_id, 0) + score\n",
    "\n",
    "    for rank, hit in enumerate(keyword_results):\n",
    "        doc_id = hit['_id']\n",
    "        score = compute_rrf(rank + 1, k)\n",
    "        rrf_scores[doc_id] = rrf_scores.get(doc_id, 0) + score\n",
    "\n",
    "    reranked_docs = sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    final_results = []\n",
    "    for doc_id, score in reranked_docs[:5]:\n",
    "        doc = next((hit for hit in (knn_results + keyword_results) if hit['_id'] == doc_id), None)\n",
    "        if doc:\n",
    "            source = doc['_source']\n",
    "            final_results.append(source)\n",
    "\n",
    "    return final_results\n",
    "\n",
    "def question_text_hybrid(q):\n",
    "    question = q['question']\n",
    "    return hybrid_query_rrf(question)\n",
    "\n",
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt += 1\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "    for line in relevance_total:\n",
    "        for rank, rel in enumerate(line):\n",
    "            if rel:\n",
    "                total_score += 1 / (rank + 1)\n",
    "                break  # Only consider the first relevant result\n",
    "    return total_score / len(relevance_total)\n",
    "\n",
    "def evaluate(documents, search_function):\n",
    "    relevance_total = []\n",
    "    for q in tqdm(documents):\n",
    "        doc_id = q['id']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['id'] == doc_id for d in results if 'id' in d]\n",
    "        relevance_total.append(relevance)\n",
    "    hit_rate_value = hit_rate(relevance_total)\n",
    "    mrr_value = mrr(relevance_total)\n",
    "    return {\n",
    "        'hit_rate': hit_rate_value,\n",
    "        'mrr': mrr_value,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "614c1308-eb1e-4364-8c7c-68b534c8bd6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cba9bc15485434fb6141ed395319d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 1.0, 'mrr': 1.0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(documents, question_text_hybrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0adb3ea-91eb-474c-9f33-34ce03c0d9f2",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2db626ac-2b6d-41e4-a1c1-3de6d4925e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1981a522-fb4a-41cc-8610-936d6812f0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are a knowledgeable medical assistant. Answer the QUESTION based solely on the information provided in the CONTEXT from the medical database.\n",
    "\n",
    "Use only the facts from the CONTEXT when formulating your answer.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "entry_template = \"\"\"\n",
    "Medical Department: {medical_department}\n",
    "Condition Type: {condition_type}\n",
    "Patient Demographics: {patient_demographics}\n",
    "Common Symptoms: {common_symptoms}\n",
    "Treatment or Management: {treatment_or_management}\n",
    "Severity: {severity}\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    context = \"\"\n",
    "    for doc in search_results:\n",
    "        context += entry_template.format(\n",
    "            medical_department=doc.get('medical_department', 'N/A'),\n",
    "            condition_type=doc.get('condition_type', 'N/A'),\n",
    "            patient_demographics=doc.get('patient_demographics', 'N/A'),\n",
    "            common_symptoms=doc.get('common_symptoms', 'N/A'),\n",
    "            treatment_or_management=doc.get('treatment_or_management', 'N/A'),\n",
    "            severity=doc.get('severity', 'N/A')\n",
    "        ) + \"\\n\\n\"\n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n",
    "\n",
    "def llm(prompt, model='gpt-4o-mini'):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def rag(query, model='gpt-4o-mini'):\n",
    "    search_results = hybrid_query_rrf(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt, model=model)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1748b159-a291-4a89-9479-9f1f2dccbc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Given that this patient is at 22 weeks of gestation and without signs of systemic infection, how does the choice of antibiotic like nitrofurantoin compare to other options in terms of safety during pregnancy, and what factors should be considered when prescribing antibiotics to pregnant patients?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afae5f3c-2a83-4dc4-a023-3ed8911ae8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best treatment for this patient, who presents with burning upon urination at 22 weeks gestation, is medication. Given her symptoms and the context provided, it suggests she may have a urinary tract infection (UTI), which is common in pregnancy. Therefore, appropriate medication such as antibiotics would be the most effective treatment option.\n"
     ]
    }
   ],
   "source": [
    "answer = rag(query)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c49c0e1-7198-4cbb-86b8-1544b7228afa",
   "metadata": {},
   "source": [
    "## Retrieval Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f5a373d-d822-40a8-9363-54459bf7307e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_question = pd.read_csv('./data/ground_truth_retrieval_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c97705d-7767-4af4-b4d0-ad7925e09525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'question': 'What are the potential causes of dysuria in a 23-year-old pregnant woman at 22 weeks gestation who presents with burning upon urination, and how do the symptoms of a urinary tract infection compare to other conditions like vulvovaginitis?'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth = df_question.to_dict(orient='records')\n",
    "ground_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "883063f2-4edf-4632-bce6-f42f83e49d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "    \n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d6c83448-59ab-4355-9a58-aa613b9e144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_search(query):\n",
    "    boost = {}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9fe7bb83-bb99-4f62-9235-8db9d2525e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['id']\n",
    "        results = search_function(q)\n",
    "        relevance = [d.get('id') == doc_id for d in results if d.get('id') is not None]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "71d47614-4355-4dcb-bfe2-0d14fca2967a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31bad2353085486faf7cb7cd78f174ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/495 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.9676767676767677, 'mrr': 0.9060942760942758}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, question_text_hybrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362b39dd-b08e-424a-92de-b9dcd665b03b",
   "metadata": {},
   "source": [
    "Baseline: \n",
    "\n",
    "Hit Rate: 96.76%,\n",
    "MRR: 90.60%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f272515-3cb3-4f1a-991d-0da85d5cf300",
   "metadata": {},
   "source": [
    "## Finding best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c757aaf8-3832-40d0-a340-43f6bcc6e142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_query_rrf(search_query: str, boost_params: Dict[str, float]) -> List[Dict]:\n",
    "    vector = embeddings.embed_query(search_query)\n",
    "    k = 60\n",
    "\n",
    "    knn_query = {\n",
    "        \"field\": \"question_answer_vector\",\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": 10,\n",
    "        \"num_candidates\": 10000,\n",
    "        \"boost\": 0.5,\n",
    "    }\n",
    "\n",
    "    fields_with_boosts = []\n",
    "    for field, boost in boost_params.items():\n",
    "        fields_with_boosts.append(f\"{field}^{boost}\")\n",
    "\n",
    "    keyword_query = {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": search_query,\n",
    "                    \"fields\": fields_with_boosts,\n",
    "                    \"type\": \"best_fields\",\n",
    "                }\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "\n",
    "    source_fields = [\n",
    "        \"id\", \"question\", \"answer\", \"medical_department\", \"condition_type\",\n",
    "        \"patient_demographics\", \"common_symptoms\", \"treatment_or_management\", \"severity\"\n",
    "    ]\n",
    "\n",
    "    knn_response = es_client.search(\n",
    "        index=index_name,\n",
    "        body={\n",
    "            \"knn\": knn_query,\n",
    "            \"size\": 10,\n",
    "            \"_source\": source_fields\n",
    "        }\n",
    "    )\n",
    "    knn_results = knn_response['hits']['hits']\n",
    "\n",
    "    keyword_response = es_client.search(\n",
    "        index=index_name,\n",
    "        body={\n",
    "            \"query\": keyword_query,\n",
    "            \"size\": 10,\n",
    "            \"_source\": source_fields\n",
    "        }\n",
    "    )\n",
    "    keyword_results = keyword_response['hits']['hits']\n",
    "\n",
    "    def compute_rrf(rank, k=60):\n",
    "        return 1.0 / (k + rank)\n",
    "\n",
    "    rrf_scores = {}\n",
    "    for rank, hit in enumerate(knn_results):\n",
    "        doc_id = hit['_id']\n",
    "        score = compute_rrf(rank + 1, k)\n",
    "        rrf_scores[doc_id] = rrf_scores.get(doc_id, 0) + score\n",
    "\n",
    "    for rank, hit in enumerate(keyword_results):\n",
    "        doc_id = hit['_id']\n",
    "        score = compute_rrf(rank + 1, k)\n",
    "        rrf_scores[doc_id] = rrf_scores.get(doc_id, 0) + score\n",
    "\n",
    "    reranked_docs = sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    final_results = []\n",
    "    for doc_id, score in reranked_docs[:5]:\n",
    "        doc = next((hit for hit in (knn_results + keyword_results) if hit['_id'] == doc_id), None)\n",
    "        if doc:\n",
    "            source = doc['_source']\n",
    "            final_results.append(source)\n",
    "\n",
    "    return final_results\n",
    "\n",
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['id']\n",
    "        results = search_function(q)\n",
    "        relevance = [d.get('id') == doc_id for d in results if d.get('id') is not None]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }\n",
    "\n",
    "def optimize(param_ranges, objective_function, n_iterations=10):\n",
    "    best_params = None\n",
    "    best_score = float('-inf')\n",
    "\n",
    "    for _ in range(n_iterations):\n",
    "        current_params = {}\n",
    "        for param, (min_val, max_val) in param_ranges.items():\n",
    "            current_params[param] = random.uniform(min_val, max_val)\n",
    "\n",
    "        current_score = objective_function(current_params)\n",
    "    \n",
    "        if current_score > best_score:\n",
    "            best_score = current_score\n",
    "            best_params = current_params\n",
    "    \n",
    "    return best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "78613b1e-acbc-4344-9703-a0234218e6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_ranges = {\n",
    "     'question': (0.0, 3.0),\n",
    "     'answer': (0.0, 3.0),\n",
    "     'medical_department': (0.0, 3.0),\n",
    "     'condition_type': (0.0, 3.0),\n",
    "     'patient_demographics': (0.0, 3.0),\n",
    "     'common_symptoms': (0.0, 3.0),\n",
    "     'treatment_or_management': (0.0, 3.0),\n",
    "     'severity': (0.0, 3.0),\n",
    "}\n",
    "\n",
    "def objective(boost_params):\n",
    "    def search_function(q):\n",
    "        return hybrid_query_rrf(q['question'], boost_params)\n",
    "    \n",
    "    results = evaluate(ground_truth, search_function)\n",
    "    return results['mrr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3048b1-22d8-4bfe-8b48-c84afdfb0ae5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_params, best_score = optimize(param_ranges, objective, n_iterations=10)\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best MRR score:\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83d06d6-ac43-4c1b-b631-fa6dbfdb099f",
   "metadata": {},
   "source": [
    "Improved Hybrid Search with RRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bd3ebdc1-de3e-4d7b-b336-948e289d5056",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def hybrid_query_rrf(search_query: str) -> List[Dict]:\n",
    "\n",
    "    best_boost_params = {\n",
    "    'question': 1.62,\n",
    "    'answer': 1.70,\n",
    "    'medical_department': 1.67,\n",
    "    'condition_type': 0.97,\n",
    "    'patient_demographics': 0.64,\n",
    "    'common_symptoms': 1.75,\n",
    "    'treatment_or_management': 0.27,\n",
    "    'severity': 1.85\n",
    "    }\n",
    "    \n",
    "    vector = embeddings.embed_query(search_query)\n",
    "    k = 60\n",
    "\n",
    "    knn_query = {\n",
    "        \"field\": \"question_answer_vector\",\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": 10,\n",
    "        \"num_candidates\": 10000,\n",
    "        \"boost\": 0.5,\n",
    "    }\n",
    "\n",
    "    fields_with_boosts = []\n",
    "    for field, boost in boost_params.items():\n",
    "        fields_with_boosts.append(f\"{field}^{boost}\")\n",
    "\n",
    "    keyword_query = {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": search_query,\n",
    "                    \"fields\": fields_with_boosts,\n",
    "                    \"type\": \"best_fields\",\n",
    "                }\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "\n",
    "    source_fields = [\n",
    "        \"id\", \"question\", \"answer\", \"medical_department\", \"condition_type\",\n",
    "        \"patient_demographics\", \"common_symptoms\", \"treatment_or_management\", \"severity\"\n",
    "    ]\n",
    "\n",
    "    knn_response = es_client.search(\n",
    "        index=index_name,\n",
    "        body={\n",
    "            \"knn\": knn_query,\n",
    "            \"size\": 10,\n",
    "            \"_source\": source_fields\n",
    "        }\n",
    "    )\n",
    "    knn_results = knn_response['hits']['hits']\n",
    "\n",
    "    keyword_response = es_client.search(\n",
    "        index=index_name,\n",
    "        body={\n",
    "            \"query\": keyword_query,\n",
    "            \"size\": 10,\n",
    "            \"_source\": source_fields\n",
    "        }\n",
    "    )\n",
    "    keyword_results = keyword_response['hits']['hits']\n",
    "\n",
    "    def compute_rrf(rank, k=60):\n",
    "        return 1.0 / (k + rank)\n",
    "\n",
    "    rrf_scores = {}\n",
    "    for rank, hit in enumerate(knn_results):\n",
    "        doc_id = hit['_id']\n",
    "        score = compute_rrf(rank + 1, k)\n",
    "        rrf_scores[doc_id] = rrf_scores.get(doc_id, 0) + score\n",
    "\n",
    "    for rank, hit in enumerate(keyword_results):\n",
    "        doc_id = hit['_id']\n",
    "        score = compute_rrf(rank + 1, k)\n",
    "        rrf_scores[doc_id] = rrf_scores.get(doc_id, 0) + score\n",
    "\n",
    "    reranked_docs = sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    final_results = []\n",
    "    for doc_id, score in reranked_docs[:5]:\n",
    "        doc = next((hit for hit in (knn_results + keyword_results) if hit['_id'] == doc_id), None)\n",
    "        if doc:\n",
    "            source = doc['_source']\n",
    "            final_results.append(source)\n",
    "\n",
    "    return final_results\n",
    "\n",
    "def question_text_hybrid(q):\n",
    "    question = q['question']\n",
    "    return hybrid_query_rrf(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d36781b9-df34-453f-9b28-8ba4b438a2ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d253ace5744df185be64f01b01b1f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/495 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.9676767676767677, 'mrr': 0.9081144781144779}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, question_text_hybrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad479f56-ffa7-4c72-8a26-997050f53324",
   "metadata": {},
   "source": [
    "Boost parameters tuned: \n",
    "\n",
    "Hit Rate: 96.76%,\n",
    "MRR: 90.81%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7e0cd1-413e-4cb3-b739-96f9c4bd65cc",
   "metadata": {},
   "source": [
    "## RAG Evaluation - LLM-as-a-Judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c1219d28-2832-4f7d-9093-1607c61463b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1_template = \"\"\"\n",
    "You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n",
    "Your task is to analyze the relevance of the generated answer compared to the original answer provided.\n",
    "Based on the relevance and similarity of the generated answer to the original answer, you will classify\n",
    "it as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Original Answer: {answer_orig}\n",
    "Generated Question: {question}\n",
    "Generated Answer: {answer_llm}\n",
    "\n",
    "Please analyze the content and context of the generated answer in relation to the original\n",
    "answer and provide your evaluation in parsable JSON without using code blocks:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2b65fc1c-4cd9-4c27-b86b-64e67594b422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The potential causes of dysuria in a 23-year-old pregnant woman at 22 weeks gestation with burning upon urination could primarily include urinary tract infections (UTIs) or other conditions affecting the urinary or genital systems, such as vulvovaginitis.\n",
      "\n",
      "When considering urinary tract infections, the symptoms typically include a burning sensation during urination, increased frequency of urination, urgency, and possibly lower abdominal discomfort. UTIs can often present with these symptoms due to the inflammation of the bladder or urethra.\n",
      "\n",
      "In contrast, vulvovaginitis may also present with a burning sensation but often includes additional symptoms such as itching, vaginal discharge, or irritation. While both conditions may feature dysuria and burning, vulvovaginitis typically has a broader spectrum of associated symptoms related to the vaginal area, compared to the more urinary-focused symptoms of a UTI.\n",
      "\n",
      "Therefore, while both UTIs and vulvovaginitis can cause dysuria, the distinction lies in the presence of additional symptoms and the underlying causes.\n"
     ]
    }
   ],
   "source": [
    "record = ground_truth[0]\n",
    "question = record['question']\n",
    "answer_orig = documents[0]['answer']\n",
    "answer_llm = rag(question)\n",
    "print(answer_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6b862f75-36d5-4b64-9767-df566bd64155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n",
      "Your task is to analyze the relevance of the generated answer compared to the original answer provided.\n",
      "Based on the relevance and similarity of the generated answer to the original answer, you will classify\n",
      "it as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
      "\n",
      "Here is the data for evaluation:\n",
      "\n",
      "Original Answer: Nitrofurantoin\n",
      "Generated Question: What are the potential causes of dysuria in a 23-year-old pregnant woman at 22 weeks gestation who presents with burning upon urination, and how do the symptoms of a urinary tract infection compare to other conditions like vulvovaginitis?\n",
      "Generated Answer: The potential causes of dysuria in a 23-year-old pregnant woman at 22 weeks gestation with burning upon urination could primarily include urinary tract infections (UTIs) or other conditions affecting the urinary or genital systems, such as vulvovaginitis.\n",
      "\n",
      "When considering urinary tract infections, the symptoms typically include a burning sensation during urination, increased frequency of urination, urgency, and possibly lower abdominal discomfort. UTIs can often present with these symptoms due to the inflammation of the bladder or urethra.\n",
      "\n",
      "In contrast, vulvovaginitis may also present with a burning sensation but often includes additional symptoms such as itching, vaginal discharge, or irritation. While both conditions may feature dysuria and burning, vulvovaginitis typically has a broader spectrum of associated symptoms related to the vaginal area, compared to the more urinary-focused symptoms of a UTI.\n",
      "\n",
      "Therefore, while both UTIs and vulvovaginitis can cause dysuria, the distinction lies in the presence of additional symptoms and the underlying causes.\n",
      "\n",
      "Please analyze the content and context of the generated answer in relation to the original\n",
      "answer and provide your evaluation in parsable JSON without using code blocks:\n",
      "\n",
      "{\n",
      "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
      "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt1_template.format(question=question, answer_orig=answer_orig, answer_llm=answer_llm)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a17a8c56-1195-41e9-8206-0f9f9517d2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"Relevance\": \"NON_RELEVANT\",\\n  \"Explanation\": \"The generated answer discusses the potential causes of dysuria and compares urinary tract infections with vulvovaginitis, but it does not mention \\'Nitrofurantoin,\\' which is the original answer provided. The focus of the original answer is on a specific medication that is relevant to treating UTIs, whereas the generated answer lacks context about treatment options and is more focused on symptoms and comparisons, making it non-relevant to the original answer.\"\\n}'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8ee417-35fc-4a1a-b73c-07892fc1a17c",
   "metadata": {},
   "source": [
    "## GPT4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8ad118d7-e915-44e0-b872-45357819c07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb753b2-9c4d-4ec1-800b-a923e5c62f12",
   "metadata": {},
   "source": [
    "## Evaluation for Prompt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "254c0e54-c285-4605-8743-365433b43899",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89933ba0-012c-486f-ad07-fd2fb1654aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in tqdm(ground_truth):\n",
    "\n",
    "    question = record['question']\n",
    "    answer_orig = documents[record['id']]['answer']\n",
    "    answer_llm = rag(question)\n",
    "    \n",
    "    prompt = prompt1_template.format(\n",
    "        question=question,\n",
    "        answer_orig=answer_orig,\n",
    "        answer_llm=answer_llm\n",
    "    )\n",
    "    evaluation = llm(prompt, model)\n",
    "    evaluation = json.loads(evaluation)\n",
    "    \n",
    "    evaluations.append((record, answer_orig, answer_llm, evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e285da75-a274-4b71-bf5a-75e7bae812c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "RELEVANT           0.911111\n",
       "PARTLY_RELEVANT    0.044444\n",
       "NON_RELEVANT       0.044444\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval = pd.DataFrame(evaluations_2, columns = ['record', 'answer_llm', 'evaluation'])\n",
    "\n",
    "df_eval['id'] = df_eval.record.apply(lambda d: d['id'])\n",
    "df_eval['question'] = df_eval.record.apply(lambda d: d['question'])\n",
    "\n",
    "df_eval['relevance'] = df_eval.evaluation.apply(lambda d: d['Relevance'])\n",
    "df_eval['explanation'] = df_eval.evaluation.apply(lambda d: d['Explanation'])\n",
    "\n",
    "del df_eval['record']\n",
    "del df_eval['evaluation']\n",
    "\n",
    "df_eval.to_csv('llm_as_a_judge_prompt2_gpt-4o-mini.csv', index=False)\n",
    "\n",
    "df_eval.relevance.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57597d62-f52a-4c8d-85d1-105719803ec7",
   "metadata": {},
   "source": [
    "## GPT4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "001f5650-d5ad-4902-8bec-df0815076f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'gpt-4o'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "555eff10-294b-41e3-83b0-07d0bbae8dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0b2393-31c2-49d2-ade0-5ebcb265072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in tqdm(ground_truth):\n",
    "\n",
    "    question = record['question']\n",
    "    answer_orig = documents[record['id']]['answer']\n",
    "    answer_llm = rag(question)\n",
    "    \n",
    "    prompt = prompt1_template.format(\n",
    "        question=question,\n",
    "        answer_orig=answer_orig,\n",
    "        answer_llm=answer_llm\n",
    "    )\n",
    "    evaluation = llm(prompt, model)\n",
    "    evaluation = json.loads(evaluation)\n",
    "    \n",
    "    evaluations.append((record, answer_orig, answer_llm, evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ca6049a6-320e-4686-8589-f4f42c742ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "NON_RELEVANT       0.677551\n",
       "PARTLY_RELEVANT    0.216327\n",
       "RELEVANT           0.106122\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval = pd.DataFrame(evaluations, columns=['record', 'answer_orig', 'answer_llm', 'evaluation'])\n",
    "    \n",
    "df_eval['id'] = df_eval.record.apply(lambda d: d['id'])\n",
    "df_eval['question'] = df_eval.record.apply(lambda d: d['question'])\n",
    "\n",
    "df_eval['relevance'] = df_eval.evaluation.apply(lambda d: d['Relevance'])\n",
    "df_eval['explanation'] = df_eval.evaluation.apply(lambda d: d['Explanation'])\n",
    "\n",
    "del df_eval['record']\n",
    "del df_eval['evaluation']\n",
    "\n",
    "df_eval.to_csv('llm_as_a_judge_prompt1_gpt-4o.csv', index=False)\n",
    "\n",
    "df_eval.relevance.value_counts(normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
